<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Standardize: Aligning Language Models with Expert-Defined Standards for Content Generation.">
  <meta name="keywords" content="standards, expert, content generation, controlled language generation, natural language generation, language models, llm">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Standardize: Aligning Language Models with Expert-Defined Standards for Content Generation</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">Standardize: Aligning Language Models with Expert-Defined Standards for Content Generation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.josephimperial.com/">Joseph Marvin Imperial</a><sup>1,2</sup></span>
            <span class="author-block">
              <a href="https://researchportal.bath.ac.uk/en/persons/gail-forey-2">Gail Forey</a><sup>1</sup></span>
            <span class="author-block">
              <a href="https://www.harishtayyarmadabushi.com/">Harish Tayyar Madabushi</a><sup>1</sup>
            </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Bath, UK,</span>
            <span class="author-block"><sup>2</sup>National University Philippines</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2402.12593"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>ArXiv</span>
                </a>
              </span>
              <!-- Github Link. -->
              <span class="link-block">
                <a href=" "
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (to be released)</span>
                </a>
              </span>
              
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        The <span class="dnerf">Standardize</span> framework is a retrieval-style ICL-based framework which aims to guide large language models to generate text content (ex. short stories) that are aligned with expert-defined standards (ex. CEFR or CCS) 
      </h2>
      <center>
      <img src="static/images/aclfig1.jpg" alt="Figure 1." width=80%>
    </center>
    </div>
  </div>
</section>
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Motivation</h2>
        <div class="content has-text-justified">
          <p><b>What are standards?</b><br> Standards are documented guidelines often containing rich detail in describing requirements, specifications, and criteria of a process or a content. These guidelines are defined and continuously improved by experts or interest groups in various domains, such as education, healthcare, and accounting.</p>

          <p><b>Why should LLMs be aligned with expert-defined standards?</b><br>
          Augmenting these expert-defined standards to an LLM to ensure that it can generate text content that aligns to the standards opens a number of advantages. Primarily, using standards will ensure that a modelâ€™s internal processes, decision-making, and outputs are consistent and reproducible, which is a prerequisite to building trustworthy AI systems. Human users will also be able to trust LLM-based systems more if they are assured that the technology also adheres to the same standards and rules that human experts follow.</p>

          <p>This study focuses on <b>content-based standards used in education and language assessment</b> (see Table below) such as the  <b><a href="https://www.coe.int/en/web/common-european-framework-reference-languages/level-descriptions">Common European Framework of Reference for Languages (CEFR)</a></b> and the <b><a href="https://www.thecorestandards.org/read-the-standards/">Common Core Standards (CCS)</a></b> which will be augmented into an LLM's text generation process. The alignment with these existing standards for any generated text material is crucial to ensure quality and consistency before being used in classroom settings. </p>

          <center><img src="static/images/standard_table.jpg" alt="standard_table"></center>

        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">The <span class="dnerf" style="font-size:120%">Standardize</span> Framework</h2>
        <!-- Interpolating. -->
        <!-- <h3 class="title is-4">Overall Model Performance</h3> -->
        <div class="content has-text-justified">
          
           <p><b><span class="dnerf" style="font-size:120%; color: blue" >Standardize</span></b> is a new retrieval-style in-context learning-based framework that exploits the rich information found in standards and transforms this into knowledge artifacts to improve the quality of content produced by generative models. </p>

           <p>As seen in the Figure above, the <b><span class="dnerf" style="font-size:120%; color: blue">Standardize</span></b> framework involves a three-part process:

          <ul>
            <li><b>Extraction of Target Specifications</b> is performed first to obtain informative tags in the prompt and to correctly match this information within the standards. For academic standards in language assessment, these specifications should provide information about  <em>who</em> will be content delivered to (target audience) and using <em>what</em> specific standard out of many (CEFR or CCS).</li>

            <li><b>Lookup and Retrieval</b> is then performed next upon extracting the target specifications. A lookup process is done to find a match with the selected standard, usually in the form of a database or an external machine-readable file. The length and complexity of a standard's level of information regarding its specifications may vary. </li>

            <li><b>Knowledge Augmentation </b> is done last. We propose a further technical augmentation of information found in standards to obtain <em>knowledge artifacts</em> in the prompts. These knowledge artifacts can range from simple additional information already present in the standard to complex representations, such as incorporating actual linguistic features to control the granularity of the generation process. </li>
          </ul>
        </p>

        </div>

        <br/>
        <div class="content has-text-justified">
          <h3 class="title is-4">Knowledge Artifacts for Standard Alignment</h3>
          <p>
          The knowledge augmentation process of <b><span class="dnerf" style="font-size:120%; color: blue">Standardize</span></b> involves the extraction of three forms of knowledge artifacts from the standard itself: 
          </p>

          <ol>
            <li><b>Aspect Information</b> (<span class="dnerf" style="font-size:120%">Standardize</span><em>-A</em>) - this is generally attributed to linguistic criteria of content with respect to its target audience. The addition of aspect criteria information ensures that the generative model will have access to <em>explicit characteristics</em> of the desired generated content in different dimensions.<br></li>

            <li><b>Exemplars</b> (<span class="dnerf" style="font-size:120%">Standardize</span><em>-E</em>) - pertain to recommended examples by experts or developers of standards for reference of users. The addition of exemplars or any artifact found in the standard that showcases gold-standard output allows the generative model to have a sense of <em>implicit knowledge</em> during the content generation process.<br></li>

            <li><b>Linguistic Flags</b> (<span class="dnerf" style="font-size:120%">Standardize</span><em>-L</em>) -  represent the controllable variables of a standard that a generative model can use to <em>explicitly steer</em> the direction of content generation. In the <b><span class="dnerf" style="font-size:120%; color: blue">Standardize</span></b> framework, this process serves as a <b>rewrite function</b> where a generative model is asked to produce an initial content first using another method prompting (e.g., aspect information), and rewrites this by comparing linguistic flag values of the initially generated content against the mean value of a gold standard dataset of the target level.<br><br>

            A <b>verbalizer</b> is used to transform the computed linguistic flags into natural language prompts. The keywords <em>increase</em> and <em>decrease</em> are used in constructing the prompts to provide a sense of direction for the generative model.

            <br></li>
          </ol>

          <center><img src="static/images/knowledge_artifacts.jpg" width=90% alt="knowledge artifacts"></center>
        </div>
    
      </section>

      <section class="section">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column is-full-width">
              <h2 class="title is-3">Results</h2>
              <div class="columns is-vcentered interpolation-panel">
              </div>
              <br/>
              
              <div class="content has-text-justified">
                <h4 class="title is-8">Standard Alignment via Overall Performance</h4>
                <p>For CEFR, we report a <b>100% increase</b> in performance with GPT-4 in precise accuracy (from 0.227 â†’ 0.480) and a <b>43% increase</b> for adjacent accuracy (from 0.630 â†’ 0.906) using the <b><span class="dnerf" style="font-size:120%; color: blue">Standardize</span></b> framework compared to the teacher style method. The open models also gained substantial boosts in performance, such as Longform up by 23%, OpenChat up by 14%, and Llama2 by 58%. In terms of adjacent accuracies, GPT-4 remained the best model for preserving the ordinality of the labels with 0.906.</p>

                <p>For CCS, we see a similar pattern where all open and closed models obtained the best performance with <b><span class="dnerf" style="font-size:120%; color: blue">Standardize</span></b>, with boosts ranging from <b>3% to 45% increase</b> using linguistic signals to refine the generated content toward the target level. </p>
                <center><img src="static/images/main_results.jpg" alt="main results"></center>
              </div>

              <div class="content has-text-justified">
                <h4 class="title is-8">Standard Alignment via Distributional Closeness</h4>
                <p>We observe that the general trend of using the best models with linguistic signals produces a <b>more stable distribution</b> across the variables it is explicitly controlling for (e.g., <em>average sentence length</em> or <em>type token diversity</em>), particularly with the CCS standards. We also notice that the distributions using <b><span class="dnerf" style="font-size:120%; color: blue">Standardize</span></b> also produce distributions closer to the mean from their corresponding gold-standard data.</p>

                <p>In terms of distributional closeness, using linguistic signals makes the quality of model generations <b>more similar</b> to the linguistic characteristics of the gold standard datasets in CEFR and CCS. Overall, these findings further strengthen the evidence of standard alignment by incorporating specific linguistic variables in the content generation process through the <b><span class="dnerf" style="font-size:120%; color: blue">Standardize</span></b> framework. </p>
                <center><img src="static/images/distribution.jpg" width=70% alt="distribution results"></center>
              </div>

              <div class="content has-text-justified">
                <h4 class="title is-8">Fluency and Diversity</h4>
                <p>In the case of fluency for models generating CEFR and CCS content, we don't see an obvious tradeoff and report relatively consistent performances with the <b><span class="dnerf" style="font-size:120%; color: blue">Standardize</span></b> setup. The best-performing model is still GPT-4 for both standards and Longform in terms of the open models. On the other hand, with the diversity metric, the most diverse batch of generated content comes from the teacher style method for CCS. But this may be on a case-to-case basis and task-dependent since we do not see the same tradeoff in performance with the CEFR standards in context-assisted story generation. </p>

                <p>Ultimately, our experiment procedure is focused on generating text content that aligns with the specified target level with respect to a standard. The standards that we applied in this study, CEFR and CCS, did not explicitly provide information on content creativity and how to measure this. Thus, we posit that creativity may be an interesting angle to explore in future works.</p>
              </div>


              <div class="content has-text-justified">
                <h2 class="title is-3">Discussion</h2>
                <h4 class="title is-8">Validity on Global Educational Context</h4>
                <p>Our experiments with the CEFR and CCS standards showcase an opportunity for the generated texts of language model interfaces such as GPT-4, which are commonly used by educators and teachers, to be aligned with international language proficiency levels. Moreover, showing the effectiveness of the <b><span class="dnerf" style="font-size:120%; color: blue">Standardize</span></b> framework on the aforementioned internationally recognized academic standards used in European and Northern American schools <b>signifies the framework's strong potential for cross-curricula application</b>. Thus, we invite future researchers to explore, validate, and propose derivations of our base framework for their own languages and language-specific standards for content generation.</p>

                <h4 class="title is-8">Towards More Personalized Content Generation</h4> 
                <p>This work contributes toward the goal of helping educators craft more personalized content for learners using the capabilities of large language models based on an assigned language proficiency level described by a standard. While we present a new task specifically targeted for the NLP community to encourage research in this direction, our results may already be useful for educators by providing context on better methods for generating level or target audience-specific texts <b>by prompting language models using information found in educational standards in the way we proposed</b>.</p>
              </div>



          <div class="content has-text-justified">
          <h3 class="title is-4">Prior Work</h3>
          <p><b>Works in Complexity Controlled NLG. </b>Research in complexity-controlled generation has been explored in the past, covering diverse facets in terms of text format, level granularity, and task variation. The work of <a href="https://aclanthology.org/D19-1166/">Agrawal and Carpuat (2019)</a> introduced controlling for specific complexity in the machine translation task. The following works of <a href="https://aclanthology.org/2023.emnlp-main.790/">Agrawal and Carpuat (2023)</a> and <a href="https://aclanthology.org/2023.emnlp-main.714/">Ribeiro et al. (2023)</a> explored grade-specific text simplification and summarization using control tokens and reinforcement learning, respectively. Currently, only two works have investigated incorporating CEFR for language learning content generation. <a href="https://aclanthology.org/2022.emnlp-industry.30/">Stowe et al. (2022)</a> and <a href="https://arxiv.org/abs/2309.05454">Imperial and Madabushi (2023)</a> both made use of CEFR-aligned text for NLG but limited their studies to two levels, A1 and C2. </p>

          <p>However, none of these works made use of the actual guideline information found in CEFR during the generation process.</p>

          <p><b>Novelty. </b>The <b><span class="dnerf" style="font-size:120%; color: blue">Standardize</span></b> framework is parallel to the work of <a href="https://proceedings.mlr.press/v202/zhou23g.html">Zhou et al. (2023)</a>, where a verbalizer is used to transform quantitative constraints into natural language for prompting, as well as the work of <a href="https://aclanthology.org/2023.tacl-1.75/">Ram et al. (2023)</a> in the lookup and retrieval phase where aspect information is added in the prompt to influence model controllability. In comparison to all the works mentioned, our studyâ€™s main novelty is capturing the <b>wholeness</b> of expert-defined standards, prioritizing fine granularity and not just one or two levels, as well as including information that can be represented as artifacts in the content generation process.</p>
        </div>  
        </section>
      

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{imperial2024standardize,
      author    = {Imperial, Joseph Marvin and Forey, Gail and Tayyar Madabushi, Harish},
      title     = {{Standardize: Aligning Language Models with Expert-Defined Standards for Content Generation}},
      year      = {2024},
     journal    = {arXiv preprint arXiv:2402.12593},
     url        = {https://arxiv.org/abs/2402.12593}
    }</code></pre>
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://akariasai.github.io/" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
